---
title: "multiple regression with ash, parallel coordinate ascent"
author: "Matthew Stephens"
date: "2019-10-07"
output: workflowr::wflow_html
editor_options:
  chunk_output_type: console
---

```{r}
library("ashr")
```

## Introduction

The idea here is to investigate a parallel approach to updating bhat in multiple regression with ash.

The basic idea is that the optimal b should be the fixed point of the following iterations:
1. r = (Y-Xb)
2. bhat = b + d^{-1}X'r
3. shat = sigma/sqrt(d)
4. b = ash(bhat,shat)

More accurately, I believe that 
if b is a fixed point of this then it will also
be a fixed point of the regular coordinate ascent (at least, something
like this should be true.)

To start with we fix g to N(0,1) to keep thing simple....

(Note that the rescaling step was supposed to allow
scaling prior and posterior by some constant, but results
suggest I may not have the details right here. Ignore this for now.)

```{r}
mr_ash_parallel_ca_fix = function(X,Y,b_init=NULL,max_iter=100,sigma=1,tol=1e-5,rescale=FALSE){
  if(is.null(b_init)){b_init = rep(0,ncol(X))}
  b = b_init
  d = Matrix::colSums(X * X)
  c = 1
  for(i in 1:max_iter){
    r = Y- X %*% b
    bhat = as.vector(b + (1/d)*(t(X) %*% r))
    s = sigma/sqrt(d)
    bhat.ash = ash(bhat,s,g=normalmix(1,0,c),fixg=TRUE)
    bnew = get_pm(bhat.ash)
    if(sum((bnew-b)^2)<tol){break;}
    b=bnew
    
    if(rescale){
      fitted = X %*% b
      v = get_psd(bhat.ash)^2
      c = sum(fitted*Y)/(sum(fitted^2) + sum(d*v)) # regress Y on fitted values
      b = c*b
    }
    
  }
  
  print(paste0("niter = ",i))
  return(b)
}

mr_ash_ca_fix = function(X,Y,b_init=NULL,max_iter=100,sigma=1,tol=1e-3,rescale=FALSE){
  if(is.null(b_init)){b_init = rep(0,ncol(X))}
  b = b_init
  p = ncol(X)
  d = Matrix::colSums(X * X)
  c = 1
  r = Y - X %*%  b
  v = rep(0,p) # vector of variances for rescaling
  for(i in 1:max_iter){
    err = 0
    for(j in 1:p){
      r = r + b[j]*X[,j] 
      bhat = (1/d[j])*sum(X[,j]* r)
      s = sigma/sqrt(d[j])
      bhat.ash = ash(bhat,s,g=normalmix(1,0,c),fixg=TRUE)
      bj_new = get_pm(bhat.ash)
      v[j] = get_psd(bhat.ash)^2 # store variances
      err = err + (b[j]-bj_new)^2
      b[j] = bj_new
      r = r - b[j]*X[,j] # recompute residuals
    }
    if(rescale){
      fitted = Y - r # so fitted = Xb
      c = sum(fitted*Y)/(sum(fitted^2) + sum(d*v)) # regress Y on fitted values
      b = c*b
      r = Y - c * fitted
    }
    if(err<tol){break;}
  }
  
  print(paste0("niter = ",i))
  return(b)
}



ridge = function(X,Y,sigma=1){
  p = ncol(X)
  S = sigma^2*diag(p) + t(X) %*% X
  bhat = solve(S, t(X) %*% Y)
  return(bhat)
}


```

A toy example to check:
```{r}
set.seed(123)
n= 100
p=10
X = matrix(rnorm(n*p),ncol=p,nrow=n)
btrue = rnorm(p)
Y = X %*% btrue + rnorm(n)

b.pca = mr_ash_parallel_ca_fix(X,Y)
b.ca = mr_ash_ca_fix(X,Y)
b.ridge = ridge(X,Y)
plot(btrue,b.ca)
points(btrue,b.pca,col=2,pch=2)
points(btrue,b.ridge,col=3,pch=3)
```

And a sparse example
```{r}
btrue[1:5]=0
Y = X %*% btrue + rnorm(n)
b.pca = mr_ash_parallel_ca_fix(X,Y)
b.ca = mr_ash_ca_fix(X,Y)
b.ridge = ridge(X,Y)
plot(btrue,b.ca)
points(btrue,b.pca,col=2,pch=2)
points(btrue,b.ridge,col=3,pch=3)
```

Now try example with X duplicated. As might have been anticipated, it fails to converge and returns a ridiculous solution that seems to be diverging off to +-infinity.
```{r}
set.seed(123)
n= 100
p=10
X = matrix(rnorm(n*p),ncol=p,nrow=n)
X = cbind(X ,X)
btrue = rnorm(2*p)
Y = X %*% btrue + rnorm(n)

b.pca = mr_ash_parallel_ca_fix(X,Y)
b.ca = mr_ash_ca_fix(X,Y)
b.ridge = ridge(X,Y)
plot(btrue,b.ca)
points(btrue,b.pca,col=2,pch=2)
points(btrue,b.ridge,col=3,pch=3)
print(b.pca)
```


Try same thing initializing from truth - it still diverges.
```{r}
b.pca = mr_ash_parallel_ca_fix(X,Y,b_init = btrue)
plot(btrue,b.pca)
```

Note that the fitted values do not fit Y at all for the parallel case. The others do.
```{r}
plot(Y,X %*% b.pca)
plot(Y,X %*% b.ca, col=, pch=2, main="fitted values for ridge and CA")
points(Y,X %*% b.ridge, col=3,pch=3)
```



See if CA matches ridge with more stringent convergence tolerance:
```{r}
b.ca = mr_ash_ca_fix(X,Y,tol = 1e-8,max_iter=1000)
plot(btrue,b.ca)
points(btrue,b.ridge,col=3,pch=3)
```


## Rescaling

Next I tried rescaling the fitted values and prior each iteration
by a constant c.
This might seem ad hoc, but I think something like this can be justified as scaling both the prior and the posterior approximation
(although results later suggest I might have the details wrong...)

In this example, rescaling definitely stabilizes the estimates...
```{r}
b.pca = mr_ash_parallel_ca_fix(X,Y,b_init = btrue,max_iter = 100,rescale=TRUE)
plot(Y,X %*% b.pca)
points(Y,X %*% b.ca, col=2, pch=2)
points(Y,X %*% b.ridge, col=3,pch=3)
```

I poked around  and found that in fact it was flipping between two different solutions. Here I run it for 99 and 98 iterations to illustrate.
```{r}
b.pca.99= mr_ash_parallel_ca_fix(X,Y,b_init = btrue,max_iter = 99,rescale=TRUE)
b.pca.98= mr_ash_parallel_ca_fix(X,Y,b_init = btrue,max_iter = 98,rescale=TRUE)

plot(b.pca,b.pca.98)
plot(b.pca,b.pca.99)
```


# trend filtering example

This example the X will be highly correlated, but not completely so.
It is designed to be challenging but easy to visualize what is going on.
```{r}
set.seed(100)
n = 100
p = n
X = matrix(0,nrow=n,ncol=n)
for(i in 1:n){
  X[i:n,i] = 1:(n-i+1)
}
btrue = rep(0,n)
btrue[40] = 8
btrue[41] = -8
Y = X %*% btrue + rnorm(n)
plot(Y)
lines(X %*% btrue)
```

The ridge solution is much better than ca, presumably due to very slow convergence.
(The solution looks better with 1000 iterations, but has still not converged; not shown
here to keep runtime down...)
```{r}
bhat_ca = mr_ash_ca_fix(X,Y,max_iter = 100,tol=1-8)
bhat_r = ridge(X,Y)
plot(Y)
lines(X %*% bhat_ca,col=2)
lines(X %*% bhat_r, col=3)
```




Parallel version goes crazy; again rescaling helps stabilize but not really working.
```{r}
bhat_pca = mr_ash_parallel_ca_fix(X,Y,max_iter= 10) 
plot(X %*% bhat_pca,col=4)

bhat_pca = mr_ash_parallel_ca_fix(X,Y,max_iter= 100, rescale=TRUE) 
plot(Y)
lines(X %*% bhat_pca,col=4)
```


