---
title: "ebpower"
author: "Matthew Stephens"
date: "2025-03-09"
output: workflowr::wflow_html
editor_options:
  chunk_output_type: console
---

```{r}
# load the ebnm library and define an ebnm_binormal function

library("ebnm")

dbinormal = function (x,s,s0,lambda,log=TRUE){
  pi0 = 0.5
  pi1 = 0.5
  s2 = s^2
  s02 = s0^2
  l0 = dnorm(x,0,sqrt(lambda^2 * s02 + s2),log=TRUE)
  l1 = dnorm(x,lambda,sqrt(lambda^2 * s02 + s2),log=TRUE)
  logsum = log(pi0*exp(l0) + pi1*exp(l1))
 
  m = pmax(l0,l1)
  logsum = m + log(pi0*exp(l0-m) + pi1*exp(l1-m))
  if (log) return(sum(logsum))
  else return(exp(sum(logsum)))
}

ebnm_binormal = function(x,s){
  x = drop(x) 
  s0 = 0.01
  lambda = optimize(function(lambda){-dbinormal(x,s,s0,lambda,log=TRUE)},
              lower = 0, upper = max(x))$minimum
  g = ashr::normalmix(pi=c(0.5,0.5), mean=c(0,lambda), sd=c(lambda * s0,lambda * s0))
  postmean = ashr::postmean(g,ashr::set_data(x,s))
  postsd = ashr::postsd(g,ashr::set_data(x,s))
  return(list(g = g, posterior = data.frame(mean=postmean,sd=postsd)))
}
```

## Introduction

I want to implement an EB version of the power update
for a symmetric data matrix S. 

## Rank 1

These are the update functions for the regular power update and
the EB version.
```{r}
# This is just the regular power update, used for initialization
power_update_r1 = function(S,v){
  newv = drop(S %*% v)
  if(!all(newv==0))
    v = newv/sqrt(sum(newv^2))
  return(v)
}

eb_power_update_r1 = function(S,v,ebnm_fn,sigma){
  newv = drop(S %*% v)
  if(!all(newv==0))
    v = ebnm_fn(newv, sigma)$posterior$mean
  if(!all(v==0))
    v = v/sqrt(sum(v^2))
  return(v)
}
```

### Non-overlapping equal group

First I simulate data under non-overlapping equal groups, so the
matrix is essentially a noisy version of a (block) identity matrix.
I set up `x` here to be the 6 factors of a hierarchical tree structure for later use, but I only use the bottom 4 factors so it is not actually a tree.
```{r}
set.seed(1)
n = 40
x = cbind(c(rep(1,n),rep(0,n)), c(rep(0,n),rep(1,n)), c(rep(1,n/2),rep(0,3*n/2)), c(rep(0,n/2), rep(1,n/2), rep(0,n)), c(rep(0,n),rep(1,n/2),rep(0,n/2)), c(rep(0,3*n/2),rep(1,n/2)))
E = matrix(0.1*rnorm(2*n*2*n),nrow=2*n)
E = E+t(E) #symmetric errors
S = x %*% diag(c(0,0,1,1,1,1)) %*% t(x) + E
image(S)
```

The first four PCs all have almost the same eigenvalues here.
The first PC is piecewise constant on the four groups, with essentially arbitrary values on each group.
```{r}
S.svd = svd(S)
S.svd$d[1:10]
pc1 = S.svd$v[,1]
plot(pc1)
```


#### Point Laplace 

Power update with point laplace: it finds one of the groups. 
```{r}
v = pc1
for(i in 1:100)
  v = eb_power_update_r1(S, v, ebnm_point_laplace, sqrt(mean(S^2)))
plot(v, ylim=c(-0.25,0.25))
```

I expected that it could find a solution with both positive and negative values (two different groups) if initialized differently. So I tried initilializing it like that, but it still found just one group. 
```{r}
v = c(rep(1,n/2),rep(-1,n/2),rep(0,n))
v = v/sqrt(sum(v^2))
for(i in 1:10){
  v = eb_power_update_r1(S, v, ebnm_point_laplace, sqrt(mean(S^2)))
}
plot(v, ylim=c(-0.25,0.25))
```

Try a different one:
```{r}
v = c(rep(0,n/2),rep(1,n/2),rep(-1,n/2),rep(0,n/2))
v = v/sqrt(sum(v^2))
for(i in 1:100){
  v = eb_power_update_r1(S, v, ebnm_point_laplace, sqrt(mean(S^2)))
}
plot(v, ylim=c(-0.25,0.25))
```

And again.. It seems to consistently want to find one group. I was a bit surprised by this, but I guess having just one group
allows it to have a sparser solution, and this is winning out here.
```{r}
v = c(rep(1,n/2),rep(0,n/2),rep(-1,n/2),rep(0,n/2))
v = v/sqrt(sum(v^2))
for(i in 1:100){
  v = eb_power_update_r1(S, v, ebnm_point_laplace, sqrt(mean(S^2)))
}
plot(v, ylim=c(-0.25,0.25))
```

#### Point Exponential

Power update with point exponential: it finds one of the groups, as I expected.
```{r}
v = pc1
for(i in 1:100){
  v = eb_power_update_r1(S, v, ebnm_point_exponential, sqrt(mean(S^2)))
}
plot(v, ylim=c(-0.25,0.25))
```

Here I initialize with the negative of the first PC, and it finds a single group again. Again I expected this. 
```{r}
v = -pc1
for(i in 1:100){
  v = eb_power_update_r1(S, v, ebnm_point_exponential, sqrt(mean(S^2)))
}
plot(v, ylim=c(-0.25,0.25))
```

#### Binormal prior

Try binormal prior; this behaves as expected.
```{r}
v = pc1
for(i in 1:100){
  v = eb_power_update_r1(S, v, ebnm_binormal, sqrt(mean(S^2)))
}
plot(v, ylim=c(-0.25,0.25))
```

However, when I try initializing with the negative of the first PC, it finds two groups. This was unexpected to me, but it makes sense in retrospect, especially as I fix the sparsity of the binormal prior to have 0.5 mass on the 0 component. Also, it is easier for the point exponential to move to sparser solutions because it is unimodal at 0. Possibly it supports the idea of running the point exponential prior before running binormal. 
```{r}
v = -pc1
for(i in 1:100){
  v = eb_power_update_r1(S, v, ebnm_binormal, sqrt(mean(S^2)))
}
plot(v, ylim=c(-0.25,0.25))
```

Here is the same thing running point exponential before binormal.
```{r}
v = -pc1
for(i in 1:100){
  v = eb_power_update_r1(S, v, ebnm_point_exponential, sqrt(mean(S^2)))
}
for(i in 1:100){
  v = eb_power_update_r1(S, v, ebnm_binormal, sqrt(mean(S^2)))
}
plot(v, ylim=c(-0.25,0.25))
```

#### Generalized Binary

The GB behaves like the binormal prior:
```{r}
v = pc1
for(i in 1:100){
  v = eb_power_update_r1(S, v, ebnm_generalized_binary, sqrt(mean(S^2)))
}
plot(v, ylim=c(-0.25,0.25))
```

Interestingly, in this example the GB prior also converges to the 2 group solution when initialized from the negative of the first PC.
```{r}
v = -pc1
for(i in 1:100){
  v = eb_power_update_r1(S, v, ebnm_generalized_binary, sqrt(mean(S^2)))
}
plot(v, ylim=c(-0.25,0.25))
```

### Non-overlapping equal group II - centered

I reran the above after centering the matrix to see how this
affects things. I expected it would change the point laplace
to find some +-1 solutions, but others should maybe not change much.

```{r}
S = S-mean(S)
```

Now it is the top 3 PCs that have almost the same eigenvalues, as
I have effectively removed one of them.
The first PC is still piecewise constant on the four groups, with essentially arbitrary values on each group.
```{r}
S.svd = svd(S)
S.svd$d[1:10]
pc1 = S.svd$v[,1]
plot(pc1)
```


#### Point Laplace 

Point laplace now finds a +-1 solution as I expected.
```{r}
v = pc1
for(i in 1:100)
  v = eb_power_update_r1(S, v, ebnm_point_laplace, sqrt(mean(S^2)))
plot(v, ylim=c(-0.25,0.25))
```


#### Point Exponential

Point exponential finds one group, as I expected.
```{r}
v = pc1
for(i in 1:100){
  v = eb_power_update_r1(S, v, ebnm_point_exponential, sqrt(mean(S^2)))
}
plot(v, ylim=c(-0.25,0.25))
```

Here I initialize with the negative of the first PC, and it finds a single group again. Again I expected this. 
```{r}
v = -pc1
for(i in 1:100){
  v = eb_power_update_r1(S, v, ebnm_point_exponential, sqrt(mean(S^2)))
}
plot(v, ylim=c(-0.25,0.25))
```

#### Binormal prior

The binormal prior behaves just as before centering:
```{r}
v = pc1
for(i in 1:100){
  v = eb_power_update_r1(S, v, ebnm_binormal, sqrt(mean(S^2)))
}
plot(v, ylim=c(-0.25,0.25))
```

```{r}
v = -pc1
for(i in 1:100){
  v = eb_power_update_r1(S, v, ebnm_binormal, sqrt(mean(S^2)))
}
plot(v, ylim=c(-0.25,0.25))
```


#### Generalized Binary

The GB also behaves the same as without centering
```{r}
v = pc1
for(i in 1:100){
  v = eb_power_update_r1(S, v, ebnm_generalized_binary, sqrt(mean(S^2)))
}
plot(v, ylim=c(-0.25,0.25))
```


```{r}
v = -pc1
for(i in 1:100){
  v = eb_power_update_r1(S, v, ebnm_generalized_binary, sqrt(mean(S^2)))
}
plot(v, ylim=c(-0.25,0.25))
```



### Tree model
Simulate data under a tree model 
```{r}
set.seed(1)
S = x %*% diag(c(1,1,1,1,1,1)) %*% t(x) + E
image(S)
```

Check the PCs. The top 2 PCs have similar eigenvalues. The first one splits the top two branches; the second one also splits them, but is almost constant. 
```{r}
S.svd = svd(S)
S.svd$d[1:10]
pc1 = cbind(S.svd$v[,1])
pc2 = cbind(S.svd$v[,2])
plot(pc1,ylim=c(-0.25,0.25))
abline(h=0)
plot(pc2,ylim=c(-0.25,0.25))
abline(h=0)
```

If one uses a completely random initialization then the eb method will often (but not always) zero things out completely on the first iteration:
```{r}
set.seed(1)
v = cbind(rnorm(2*n))
v= v/sqrt(sum(v^2))
sigma = sqrt(mean(S^2))
v = eb_power_update_r1(S,v,ebnm_point_laplace,sigma)
plot(v,ylim=c(-0.25,0.25))
abline(h=0)
```

We can help avoid this here by doing a single iteration of the power method before moving to EB (because the matrix is very low rank the single iteration moves us quickly to the right subspace). Here the point-laplace gives a 0-1 split of the top 2 branches.
```{r}
set.seed(1)
v = cbind(rnorm(2*n))
v= v/sqrt(sum(v^2))
sigma = sqrt(mean(S^2))

v = power_update_r1(S,v)
plot(v,ylim=c(-0.25,0.25))
for(i in 1:100){
  v = eb_power_update_r1(S,v,ebnm_point_laplace,sigma)
}
plot(v,ylim=c(-0.25,0.25))
abline(h=0)
```

The point exponential performs similarly, but the "0" part is slightly non-zero. This is possibly due to the posterior mean reflecting a small probability of coming from the exponential part. (This is not a convergence issue - it remains with more iterations, not shown.)
```{r}
set.seed(1)
v = cbind(rnorm(2*n))
v= v/sqrt(sum(v^2))
sigma = sqrt(mean(S^2))

v = power_update_r1(S,v)
plot(v,ylim=c(-0.25,0.25))
for(i in 1:100){
  v = eb_power_update_r1(S,v,ebnm_point_exponential,sigma)
}
plot(v,ylim=c(-0.25,0.25))
abline(h=0)
```


Try further running binormal - it moves things to 0.
```{r}
for(i in 1:100){
  v = eb_power_update_r1(S,v,ebnm_binormal,sigma)
}
plot(v, ylim=c(-0.25,0.25))
abline(h=0)
```

Here running binormal from a random starting point gives the constant vector. (Not a bad solution in principle, but not what we are looking for)
```{r}
set.seed(1)
v = cbind(rnorm(2*n))
v= v/sqrt(sum(v^2))
sigma = sqrt(mean(S^2))

v = power_update_r1(S,v)
plot(v,ylim=c(-0.25,0.25))
for(i in 1:100){
  v = eb_power_update_r1(S,v,ebnm_binormal,sigma)
}
plot(v,ylim=c(-0.25,0.25))
abline(h=0)
```


### Tree model - stronger diagonal

To try to make things interesting I make the diagonal stronger,
so that there is ambiguity about whether to split on the top branch or the
population-specific branches. I'm hoping to create a situation where
the point exponential gives us a non tree-like solution that captures no single branch (ie captures multiple branches).

```{r}
set.seed(1)
S = x %*% diag(c(1,1,8,8,8,8)) %*% t(x) + E
image(S)
```

Check the PCs. They don't change much from the original symmetric case.
```{r}
S.svd = svd(S)
S.svd$d[1:10]
pc1 = cbind(S.svd$v[,1])
pc2 = cbind(S.svd$v[,2])
plot(pc1,ylim=c(-0.25,0.25))
abline(h=0)
plot(pc2,ylim=c(-0.25,0.25))
abline(h=0)
```

Again, point-laplace gives a 0-1 split of the top 2 branches (even though initialized here from something closer to a split of 3 populations vs 1)
```{r}
set.seed(1)
v = cbind(rnorm(2*n))
v= v/sqrt(sum(v^2))
sigma = sqrt(mean(S^2))

v = power_update_r1(S,v)
plot(v,ylim=c(-0.25,0.25))
for(i in 1:100){
  v = eb_power_update_r1(S,v,ebnm_point_laplace,sigma)
}
plot(v,ylim=c(-0.25,0.25))
abline(h=0)
```

The point exponential performs similarly, but the "0" part again slightly non-zero. 
```{r}
set.seed(1)
v = cbind(rnorm(2*n))
v= v/sqrt(sum(v^2))
sigma = sqrt(mean(S^2))

v = power_update_r1(S,v)
plot(v,ylim=c(-0.25,0.25))
for(i in 1:100){
  v = eb_power_update_r1(S,v,ebnm_point_exponential,sigma)
}
plot(v,ylim=c(-0.25,0.25))
abline(h=0)
```


This time we use generalized binary, which like the binormal moves that non-zero element to 0.
```{r}
for(i in 1:100){
  v = eb_power_update_r1(S,v,ebnm_generalized_binary,sigma)
}
plot(v, ylim=c(-0.25,0.25))
abline(h=0)
```

Here running binormal from a random starting point gives a 3-population split. It is another illustration of why running binormal from a random starting point may not be a good idea. 
```{r}
set.seed(1)
v = cbind(rnorm(2*n))
v= v/sqrt(sum(v^2))
sigma = sqrt(mean(S^2))

v = power_update_r1(S,v)
plot(v,ylim=c(-0.25,0.25))
for(i in 1:100){
  v = eb_power_update_r1(S,v,ebnm_binormal,sigma)
}
plot(v,ylim=c(-0.25,0.25))
abline(h=0)
```


The same happens for the GB prior:
```{r}
set.seed(1)
v = cbind(rnorm(2*n))
v= v/sqrt(sum(v^2))
sigma = sqrt(mean(S^2))

v = power_update_r1(S,v)
plot(v,ylim=c(-0.25,0.25))
for(i in 1:100){
  v = eb_power_update_r1(S,v,ebnm_generalized_binary,sigma)
}
plot(v,ylim=c(-0.25,0.25))
abline(h=0)
```

### Tree model - centered

Now we try centering the tree.
```{r}
set.seed(1)
S = x %*% diag(c(1,1,1,1,1,1)) %*% t(x) + E
S = S-mean(S)
image(S)
```

Check the PCs. The top 2 PCs have similar eigenvalues. The first one splits the top two branches; the second one also splits them, but is almost constant. 
```{r}
S.svd = svd(S)
S.svd$d[1:10]
pc1 = cbind(S.svd$v[,1])
pc2 = cbind(S.svd$v[,2])
plot(pc1,ylim=c(-0.25,0.25))
abline(h=0)
plot(pc2,ylim=c(-0.25,0.25))
abline(h=0)
```

Now the point-laplace gives a +-1 split of the top 2 branches.
```{r}
set.seed(1)
v = cbind(rnorm(2*n))
v= v/sqrt(sum(v^2))
sigma = sqrt(mean(S^2))

v = power_update_r1(S,v)
plot(v,ylim=c(-0.25,0.25))
for(i in 1:100){
  v = eb_power_update_r1(S,v,ebnm_point_laplace,sigma)
}
plot(v,ylim=c(-0.25,0.25))
abline(h=0)
```

The point exponential produces a 0-1 split. 
```{r}
set.seed(1)
v = cbind(rnorm(2*n))
v= v/sqrt(sum(v^2))
sigma = sqrt(mean(S^2))

v = power_update_r1(S,v)
plot(v,ylim=c(-0.25,0.25))
for(i in 1:100){
  v = eb_power_update_r1(S,v,ebnm_point_exponential,sigma)
}
plot(v,ylim=c(-0.25,0.25))
abline(h=0)
```


Here running binormal from a random starting point also gives the 0-1 split.
```{r}
set.seed(1)
v = cbind(rnorm(2*n))
v= v/sqrt(sum(v^2))
sigma = sqrt(mean(S^2))

v = power_update_r1(S,v)
plot(v,ylim=c(-0.25,0.25))
for(i in 1:100){
  v = eb_power_update_r1(S,v,ebnm_binormal,sigma)
}
plot(v,ylim=c(-0.25,0.25))
abline(h=0)
```

## Rank K

```{r}
# model is  S \sim VDV' + E with eb prior on V
eb_power_update = function(S,v,d,ebnm_fn){
  K = ncol(v)
  sigma2=mean((S-v %*% diag(d,nrow=length(d)) %*% t(v))^2)
  
  for(k in 1:K){
    U = v[,-k,drop=FALSE]
    D = diag(d[-k],nrow=length(d[-k]))
    
    newv = (S %*% v[,k,drop=FALSE] - U %*% D %*% t(U) %*% v[,k,drop=FALSE] )
    if(!all(newv==0)){
      fit.ebnm = ebnm_fn(newv,sqrt(sigma2))        
      newv = fit.ebnm$posterior$mean
      if(!all(newv==0)){
        newv = newv/sqrt(sum(newv^2 + fit.ebnm$posterior$sd^2))
      } 
    }
    v[,k] = newv
    d[k] = t(v[,k]) %*% S %*% v[,k] - t(v[,k]) %*% U %*% D %*% t(U) %*% v[,k] 
  }
  return(list(v=v,d=d))
}

#helper function
compute_sqerr = function(S,fit){
  sum((S-fit$v %*% diag(fit$d,nrow=length(fit$d)) %*% t(fit$v))^2)
}

# a random initialization
random_init = function(S,K,nonneg = FALSE){
  n = nrow(S)
  v = matrix(nrow=n,ncol=K)
  
  for(k in 1:K){
    v[,k] = cbind(rnorm(n)) # initialize v
    if(nonneg)
        v[,k] = pmax(v[,k],0)
    v[,k] = v[,k]/sum(v[,k]^2)
  }
  d = rep(1e-8,K)
  return(list(v=v,d=d))
}
```


## Tree structured data

Simulate data under a tree model (with very small errors)
```{r}
set.seed(1)
n = 40
x = cbind(c(rep(1,n),rep(0,n)), c(rep(0,n),rep(1,n)), c(rep(1,n/2),rep(0,3*n/2)), c(rep(0,n/2), rep(1,n/2), rep(0,n)), c(rep(0,n),rep(1,n/2),rep(0,n/2)), c(rep(0,3*n/2),rep(1,n/2)))
E = matrix(0.01*rexp(2*n*2*n),nrow=2*n)
E = E+t(E) #symmetric errors
S = x %*% diag(c(1,1,1,1,1,1)) %*% t(x) + E
image(S)
```


### Run multiple factors

Here I run with $K=9$ and point-exponential. It finds a rank 4 solution, essentially zeroing out the other 5. 
One can compare this with non-negative without the EB approach [here](power_nneg.html). 
```{r}
set.seed(2)
fit = random_init(S,9,nonneg=TRUE)
err = rep(0,10)
err[1] = sum((S-fit$v %*% diag(fit$d) %*% t(fit$v))^2)
for(i in 2:100){
  fit = eb_power_update(S,fit$v,fit$d,ebnm_point_exponential)
  err[i] = sum((S-fit$v %*% diag(fit$d) %*% t(fit$v))^2)
}
plot(err)

par(mfcol=c(3,3),mai=rep(0.3,4))
for(i in 1:9){plot(fit$v[,i],main=paste0(trunc(fit$d[i])))}
```

Here I try the generalized binary prior. So far I'm finding this does not work well, especially if started from random starting point. I debugged and found that what happens is that generally the v are bounded away from 0. So the gb prior puts all its weight on the non-null normal component and does not shrink anything. (Is it worth using a laplace for the non-null component?) The point exponential does not have that problem - it shrinks the smallest values towards 0, and eventually gets to a point where everything is 0. It seems clear that using the gb prior from random initialization is not going to work.

```{r}
set.seed(2)
fit = random_init(S,9, nonneg=TRUE)
err = rep(0,10)
err[1] = sum((S-fit$v %*% diag(fit$d) %*% t(fit$v))^2)
 
for(i in 2:10){
  fit = eb_power_update(S,fit$v,fit$d,ebnm_generalized_binary)
  err[i] = sum((S-fit$v %*% diag(fit$d) %*% t(fit$v))^2)
}
plot(err)

par(mfcol=c(3,3),mai=rep(0.3,4))
for(i in 1:9){plot(fit$v[,i],main=paste0(trunc(fit$d[i])))}
```

Here we try initializing GB with point-exponential. It only changes the fit very little.
```{r}
set.seed(2)
fit = random_init(S,9,nonneg=TRUE)

for(i in 1:100){
  fit = eb_power_update(S,fit$v,fit$d,ebnm_point_exponential)
}
par(mfcol=c(3,3),mai=rep(0.3,4))
for(i in 1:9){plot(fit$v[,i],main=paste0(trunc(fit$d[i])))}

for(i in 1:100){
  fit = eb_power_update(S,fit$v,fit$d,ebnm_generalized_binary)
}
par(mfcol=c(3,3),mai=rep(0.3,4))
for(i in 1:9){plot(fit$v[,i],main=paste0(trunc(fit$d[i])))}
```

The binormal prior provides a more bimodal solution. (Note: although not seen here, I have seen issues with it including a factor that puts two non-neighboring populations together.)
```{r}
for(i in 1:100){
  fit = eb_power_update(S,fit$v,fit$d,ebnm_binormal)
  err[i] = compute_sqerr(S,fit)
}
par(mfcol=c(3,3),mai=rep(0.3,4))
for(i in 1:9){plot(fit$v[,i],main=paste0(trunc(fit$d[i])))}

for(i in 1:100){
  fit = eb_power_update(S,fit$v,fit$d,ebnm_binormal)
}
par(mfcol=c(3,3),mai=rep(0.3,4))
for(i in 1:9){plot(fit$v[,i],main=paste0(trunc(fit$d[i])))}

```

## SVD initialization

I'm going to try initializing with SVD, then running point-laplace, then 
running GB, similar to the strategy in the GBCD paper. (Note: here I initialize with the svd values for d; an alternative is to set these to be very small and just use the v from svd to initialize.)
```{r}
set.seed(2)
S.svd = svd(S)

fit = list(v=S.svd$u[,1:4],d=S.svd$d[1:4]) #rep(1e-8,4)) #init d to be very small

err = rep(0,10)
err[1] = compute_sqerr(S,fit)
 
for(i in 2:100){
  fit = eb_power_update(S,fit$v,fit$d,ebnm_point_laplace)
  err[i] = compute_sqerr(S,fit)
}
par(mfcol=c(3,3),mai=rep(0.3,4))
for(i in 1:4){plot(fit$v[,i],main=paste0(trunc(fit$d[i])))}
```

```{r}
split_v = function(v){
  v = cbind(pmax(v,0),pmax(-v,0))
}

fit$v = split_v(fit$v)
fit$d= rep(fit$d/2,2)

for(i in 2:100){
  fit = eb_power_update(S,fit$v,fit$d,ebnm_point_exponential)
  err[i] = compute_sqerr(S,fit)
}
par(mfcol=c(3,3),mai=rep(0.3,4))
for(i in 1:8){plot(fit$v[,i],main=paste0(trunc(fit$d[i])))}
fit.pe = fit # save for later use

for(i in 2:200){
  fit = eb_power_update(S,fit$v,fit$d,ebnm_generalized_binary)
  err[i] = compute_sqerr(S,fit)
}
par(mfcol=c(3,3),mai=rep(0.3,4))
for(i in 1:8){plot(fit$v[,i],main=paste0(trunc(fit$d[i])))}
```

Try binormal instead, initialized from point-exp. This works better.
```{r}
fit = fit.pe
for(i in 2:200){
  fit = eb_power_update(S,fit$v,fit$d,ebnm_binormal)
  err[i] = compute_sqerr(S,fit)
}
par(mfcol=c(3,3),mai=rep(0.3,4))
for(i in 1:8){plot(fit$v[,i],main=paste0(trunc(fit$d[i])))}
```

