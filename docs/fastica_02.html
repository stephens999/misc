<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />


<meta name="author" content="Matthew Stephens" />

<meta name="date" content="2025-10-27" />

<title>fastica_02</title>

<script src="site_libs/header-attrs-2.29/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui-1.13.2/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/textmate.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<link rel="icon" href="https://github.com/workflowr/workflowr-assets/raw/main/img/reproducible.png">
<!-- Add a small amount of space between sections. -->
<style type="text/css">
div.section {
  padding-top: 12px;
}
</style>



<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>









<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark the anchor link active (and if it's in a dropdown, also mark that active)
  var dropdown = menuAnchor.closest('li.dropdown');
  if (window.bootstrap) { // Bootstrap 4+
    menuAnchor.addClass('active');
    dropdown.find('> .dropdown-toggle').addClass('active');
  } else { // Bootstrap 3
    menuAnchor.parent().addClass('active');
    dropdown.addClass('active');
  }

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before, .tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "\e259";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "\e258";
  font-family: 'Glyphicons Halflings';
  border: none;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">misc</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://github.com/stephens999/misc">source</a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">fastica_02</h1>
<h4 class="author">Matthew Stephens</h4>
<h4 class="date">2025-10-27</h4>

</div>


<p>
<button type="button" class="btn btn-default btn-workflowr btn-workflowr-report" data-toggle="collapse" data-target="#workflowr-report">
<span class="glyphicon glyphicon-list" aria-hidden="true"></span>
workflowr <span class="glyphicon glyphicon-ok text-success"
aria-hidden="true"></span>
</button>
</p>
<div id="workflowr-report" class="collapse">
<ul class="nav nav-tabs">
<li class="active">
<a data-toggle="tab" href="#summary">Summary</a>
</li>
<li>
<a data-toggle="tab" href="#checks"> Checks <span
class="glyphicon glyphicon-ok text-success" aria-hidden="true"></span>
</a>
</li>
<li>
<a data-toggle="tab" href="#versions">Past versions</a>
</li>
</ul>
<div class="tab-content">
<div id="summary" class="tab-pane fade in active">
<p>
<strong>Last updated:</strong> 2025-11-14
</p>
<p>
<strong>Checks:</strong> <span
class="glyphicon glyphicon-ok text-success" aria-hidden="true"></span> 7
<span class="glyphicon glyphicon-exclamation-sign text-danger"
aria-hidden="true"></span> 0
</p>
<p>
<strong>Knit directory:</strong> <code>misc/analysis/</code> <span
class="glyphicon glyphicon-question-sign" aria-hidden="true"
title="This is the local directory in which the code in this file was executed.">
</span>
</p>
<p>
This reproducible <a href="https://rmarkdown.rstudio.com">R Markdown</a>
analysis was created with <a
  href="https://github.com/workflowr/workflowr">workflowr</a> (version
1.7.1). The <em>Checks</em> tab describes the reproducibility checks
that were applied when the results were created. The <em>Past
versions</em> tab lists the development history.
</p>
<hr>
</div>
<div id="checks" class="tab-pane fade">
<div id="workflowr-checks" class="panel-group">
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongRMarkdownfilestronguptodate">
<span class="glyphicon glyphicon-ok text-success"
aria-hidden="true"></span> <strong>R Markdown file:</strong> up-to-date
</a>
</p>
</div>
<div id="strongRMarkdownfilestronguptodate"
class="panel-collapse collapse">
<div class="panel-body">
<p>Great! Since the R Markdown file has been committed to the Git
repository, you know the exact version of the code that produced these
results.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongEnvironmentstrongempty">
<span class="glyphicon glyphicon-ok text-success"
aria-hidden="true"></span> <strong>Environment:</strong> empty </a>
</p>
</div>
<div id="strongEnvironmentstrongempty" class="panel-collapse collapse">
<div class="panel-body">
<p>Great job! The global environment was empty. Objects defined in the
global environment can affect the analysis in your R Markdown file in
unknown ways. For reproduciblity it’s best to always run the code in an
empty environment.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongSeedstrongcodesetseed1code">
<span class="glyphicon glyphicon-ok text-success"
aria-hidden="true"></span> <strong>Seed:</strong>
<code>set.seed(1)</code> </a>
</p>
</div>
<div id="strongSeedstrongcodesetseed1code"
class="panel-collapse collapse">
<div class="panel-body">
<p>The command <code>set.seed(1)</code> was run prior to running the
code in the R Markdown file. Setting a seed ensures that any results
that rely on randomness, e.g. subsampling or permutations, are
reproducible.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongSessioninformationstrongrecorded">
<span class="glyphicon glyphicon-ok text-success"
aria-hidden="true"></span> <strong>Session information:</strong>
recorded </a>
</p>
</div>
<div id="strongSessioninformationstrongrecorded"
class="panel-collapse collapse">
<div class="panel-body">
<p>Great job! Recording the operating system, R version, and package
versions is critical for reproducibility.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongCachestrongnone">
<span class="glyphicon glyphicon-ok text-success"
aria-hidden="true"></span> <strong>Cache:</strong> none </a>
</p>
</div>
<div id="strongCachestrongnone" class="panel-collapse collapse">
<div class="panel-body">
<p>Nice! There were no cached chunks for this analysis, so you can be
confident that you successfully produced the results during this
run.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongFilepathsstrongrelative">
<span class="glyphicon glyphicon-ok text-success"
aria-hidden="true"></span> <strong>File paths:</strong> relative </a>
</p>
</div>
<div id="strongFilepathsstrongrelative" class="panel-collapse collapse">
<div class="panel-body">
<p>Great job! Using relative paths to the files within your workflowr
project makes it easier to run your code on other machines.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongRepositoryversionstrongahrefhttpsgithubcomstephens999misctreea415272e8d25afa0d7c854d7b15a57f22f6672e4targetblanka415272a">
<span class="glyphicon glyphicon-ok text-success"
aria-hidden="true"></span> <strong>Repository version:</strong>
<a href="https://github.com/stephens999/misc/tree/a415272e8d25afa0d7c854d7b15a57f22f6672e4" target="_blank">a415272</a>
</a>
</p>
</div>
<div
id="strongRepositoryversionstrongahrefhttpsgithubcomstephens999misctreea415272e8d25afa0d7c854d7b15a57f22f6672e4targetblanka415272a"
class="panel-collapse collapse">
<div class="panel-body">
<p>
Great! You are using Git for version control. Tracking code development
and connecting the code version to the results is critical for
reproducibility.
</p>
<p>
The results in this page were generated with repository version
<a href="https://github.com/stephens999/misc/tree/a415272e8d25afa0d7c854d7b15a57f22f6672e4" target="_blank">a415272</a>.
See the <em>Past versions</em> tab to see a history of the changes made
to the R Markdown and HTML files.
</p>
<p>
Note that you need to be careful to ensure that all relevant files for
the analysis have been committed to Git prior to generating the results
(you can use <code>wflow_publish</code> or
<code>wflow_git_commit</code>). workflowr only checks the R Markdown
file, but you know if there are other scripts or data files that it
depends on. Below is the status of the Git repository when the results
were generated:
</p>
<pre><code>
Ignored files:
    Ignored:    .DS_Store
    Ignored:    .Rhistory
    Ignored:    .Rproj.user/
    Ignored:    analysis/.RData
    Ignored:    analysis/.Rhistory
    Ignored:    analysis/ALStruct_cache/
    Ignored:    data/.Rhistory
    Ignored:    data/methylation-data-for-matthew.rds
    Ignored:    data/pbmc/
    Ignored:    data/pbmc_purified.RData

Untracked files:
    Untracked:  .dropbox
    Untracked:  Icon
    Untracked:  analysis/GHstan.Rmd
    Untracked:  analysis/GTEX-cogaps.Rmd
    Untracked:  analysis/PACS.Rmd
    Untracked:  analysis/Rplot.png
    Untracked:  analysis/SPCAvRP.rmd
    Untracked:  analysis/abf_comparisons.Rmd
    Untracked:  analysis/admm_02.Rmd
    Untracked:  analysis/admm_03.Rmd
    Untracked:  analysis/bispca.Rmd
    Untracked:  analysis/cache/
    Untracked:  analysis/cholesky.Rmd
    Untracked:  analysis/compare-transformed-models.Rmd
    Untracked:  analysis/cormotif.Rmd
    Untracked:  analysis/cp_ash.Rmd
    Untracked:  analysis/eQTL.perm.rand.pdf
    Untracked:  analysis/eb_power2.Rmd
    Untracked:  analysis/eb_prepilot.Rmd
    Untracked:  analysis/eb_var.Rmd
    Untracked:  analysis/ebpmf1.Rmd
    Untracked:  analysis/ebpmf_sla_text.Rmd
    Untracked:  analysis/ebspca_sims.Rmd
    Untracked:  analysis/explore_psvd.Rmd
    Untracked:  analysis/fa_check_identify.Rmd
    Untracked:  analysis/fa_iterative.Rmd
    Untracked:  analysis/fastica_centered.Rmd
    Untracked:  analysis/flash_cov_overlapping_groups_init.Rmd
    Untracked:  analysis/flash_test_tree.Rmd
    Untracked:  analysis/flashier_newgroups.Rmd
    Untracked:  analysis/flashier_nmf_triples.Rmd
    Untracked:  analysis/flashier_pbmc.Rmd
    Untracked:  analysis/flashier_snn_shifted_prior.Rmd
    Untracked:  analysis/greedy_ebpmf_exploration_00.Rmd
    Untracked:  analysis/ieQTL.perm.rand.pdf
    Untracked:  analysis/lasso_em_03.Rmd
    Untracked:  analysis/m6amash.Rmd
    Untracked:  analysis/mash_bhat_z.Rmd
    Untracked:  analysis/mash_ieqtl_permutations.Rmd
    Untracked:  analysis/methylation_example.Rmd
    Untracked:  analysis/mixsqp.Rmd
    Untracked:  analysis/mr.ash_lasso_init.Rmd
    Untracked:  analysis/mr.mash.test.Rmd
    Untracked:  analysis/mr_ash_modular.Rmd
    Untracked:  analysis/mr_ash_parameterization.Rmd
    Untracked:  analysis/mr_ash_ridge.Rmd
    Untracked:  analysis/mv_gaussian_message_passing.Rmd
    Untracked:  analysis/nejm.Rmd
    Untracked:  analysis/nmf_bg.Rmd
    Untracked:  analysis/nonneg_underapprox.Rmd
    Untracked:  analysis/normal_conditional_on_r2.Rmd
    Untracked:  analysis/normalize.Rmd
    Untracked:  analysis/pbmc.Rmd
    Untracked:  analysis/pca_binary_weighted.Rmd
    Untracked:  analysis/pca_l1.Rmd
    Untracked:  analysis/poisson_nmf_approx.Rmd
    Untracked:  analysis/poisson_shrink.Rmd
    Untracked:  analysis/poisson_transform.Rmd
    Untracked:  analysis/qrnotes.txt
    Untracked:  analysis/ridge_iterative_02.Rmd
    Untracked:  analysis/ridge_iterative_splitting.Rmd
    Untracked:  analysis/samps/
    Untracked:  analysis/sc_bimodal.Rmd
    Untracked:  analysis/shrinkage_comparisons_changepoints.Rmd
    Untracked:  analysis/susie_cov.Rmd
    Untracked:  analysis/susie_en.Rmd
    Untracked:  analysis/susie_z_investigate.Rmd
    Untracked:  analysis/svd-timing.Rmd
    Untracked:  analysis/temp.RDS
    Untracked:  analysis/temp.Rmd
    Untracked:  analysis/test-figure/
    Untracked:  analysis/test.Rmd
    Untracked:  analysis/test.Rpres
    Untracked:  analysis/test.md
    Untracked:  analysis/test_qr.R
    Untracked:  analysis/test_sparse.Rmd
    Untracked:  analysis/tree_dist_top_eigenvector.Rmd
    Untracked:  analysis/z.txt
    Untracked:  code/coordinate_descent_symNMF.R
    Untracked:  code/multivariate_testfuncs.R
    Untracked:  code/rqb.hacked.R
    Untracked:  data/4matthew/
    Untracked:  data/4matthew2/
    Untracked:  data/E-MTAB-2805.processed.1/
    Untracked:  data/ENSG00000156738.Sim_Y2.RDS
    Untracked:  data/GDS5363_full.soft.gz
    Untracked:  data/GSE41265_allGenesTPM.txt
    Untracked:  data/Muscle_Skeletal.ACTN3.pm1Mb.RDS
    Untracked:  data/P.rds
    Untracked:  data/Thyroid.FMO2.pm1Mb.RDS
    Untracked:  data/bmass.HaemgenRBC2016.MAF01.Vs2.MergedDataSources.200kRanSubset.ChrBPMAFMarkerZScores.vs1.txt.gz
    Untracked:  data/bmass.HaemgenRBC2016.Vs2.NewSNPs.ZScores.hclust.vs1.txt
    Untracked:  data/bmass.HaemgenRBC2016.Vs2.PreviousSNPs.ZScores.hclust.vs1.txt
    Untracked:  data/eb_prepilot/
    Untracked:  data/finemap_data/fmo2.sim/b.txt
    Untracked:  data/finemap_data/fmo2.sim/dap_out.txt
    Untracked:  data/finemap_data/fmo2.sim/dap_out2.txt
    Untracked:  data/finemap_data/fmo2.sim/dap_out2_snp.txt
    Untracked:  data/finemap_data/fmo2.sim/dap_out_snp.txt
    Untracked:  data/finemap_data/fmo2.sim/data
    Untracked:  data/finemap_data/fmo2.sim/fmo2.sim.config
    Untracked:  data/finemap_data/fmo2.sim/fmo2.sim.k
    Untracked:  data/finemap_data/fmo2.sim/fmo2.sim.k4.config
    Untracked:  data/finemap_data/fmo2.sim/fmo2.sim.k4.snp
    Untracked:  data/finemap_data/fmo2.sim/fmo2.sim.ld
    Untracked:  data/finemap_data/fmo2.sim/fmo2.sim.snp
    Untracked:  data/finemap_data/fmo2.sim/fmo2.sim.z
    Untracked:  data/finemap_data/fmo2.sim/pos.txt
    Untracked:  data/logm.csv
    Untracked:  data/m.cd.RDS
    Untracked:  data/m.cdu.old.RDS
    Untracked:  data/m.new.cd.RDS
    Untracked:  data/m.old.cd.RDS
    Untracked:  data/mainbib.bib.old
    Untracked:  data/mat.csv
    Untracked:  data/mat.txt
    Untracked:  data/mat_new.csv
    Untracked:  data/matrix_lik.rds
    Untracked:  data/paintor_data/
    Untracked:  data/running_data_chris.csv
    Untracked:  data/running_data_matthew.csv
    Untracked:  data/temp.txt
    Untracked:  data/y.txt
    Untracked:  data/y_f.txt
    Untracked:  data/zscore_jointLCLs_m6AQTLs_susie_eQTLpruned.rds
    Untracked:  data/zscore_jointLCLs_random.rds
    Untracked:  explore_udi.R
    Untracked:  output/fit.k10.rds
    Untracked:  output/fit.nn.pbmc.purified.rds
    Untracked:  output/fit.nn.rds
    Untracked:  output/fit.nn.s.001.rds
    Untracked:  output/fit.nn.s.01.rds
    Untracked:  output/fit.nn.s.1.rds
    Untracked:  output/fit.nn.s.10.rds
    Untracked:  output/fit.snn.s.001.rds
    Untracked:  output/fit.snn.s.01.nninit.rds
    Untracked:  output/fit.snn.s.01.rds
    Untracked:  output/fit.varbvs.RDS
    Untracked:  output/fit2.nn.pbmc.purified.rds
    Untracked:  output/glmnet.fit.RDS
    Untracked:  output/snn07.txt
    Untracked:  output/snn34.txt
    Untracked:  output/test.bv.txt
    Untracked:  output/test.gamma.txt
    Untracked:  output/test.hyp.txt
    Untracked:  output/test.log.txt
    Untracked:  output/test.param.txt
    Untracked:  output/test2.bv.txt
    Untracked:  output/test2.gamma.txt
    Untracked:  output/test2.hyp.txt
    Untracked:  output/test2.log.txt
    Untracked:  output/test2.param.txt
    Untracked:  output/test3.bv.txt
    Untracked:  output/test3.gamma.txt
    Untracked:  output/test3.hyp.txt
    Untracked:  output/test3.log.txt
    Untracked:  output/test3.param.txt
    Untracked:  output/test4.bv.txt
    Untracked:  output/test4.gamma.txt
    Untracked:  output/test4.hyp.txt
    Untracked:  output/test4.log.txt
    Untracked:  output/test4.param.txt
    Untracked:  output/test5.bv.txt
    Untracked:  output/test5.gamma.txt
    Untracked:  output/test5.hyp.txt
    Untracked:  output/test5.log.txt
    Untracked:  output/test5.param.txt

Unstaged changes:
    Modified:   .gitignore
    Modified:   analysis/eb_snmu.Rmd
    Modified:   analysis/ebnm_binormal.Rmd
    Modified:   analysis/ebpower.Rmd
    Modified:   analysis/flashier_log1p.Rmd
    Modified:   analysis/flashier_sla_text.Rmd
    Modified:   analysis/logistic_z_scores.Rmd
    Modified:   analysis/mr_ash_pen.Rmd
    Modified:   analysis/nmu_em.Rmd
    Modified:   analysis/susie_flash.Rmd
    Modified:   analysis/tap_free_energy.Rmd
    Modified:   misc.Rproj

</code></pre>
<p>
Note that any generated files, e.g. HTML, png, CSS, etc., are not
included in this status report because it is ok for generated content to
have uncommitted changes.
</p>
</div>
</div>
</div>
</div>
<hr>
</div>
<div id="versions" class="tab-pane fade">
<p>
These are the previous versions of the repository in which changes were
made to the R Markdown (<code>analysis/fastica_02.Rmd</code>) and HTML
(<code>docs/fastica_02.html</code>) files. If you’ve configured a remote
Git repository (see <code>?wflow_git_remote</code>), click on the
hyperlinks in the table below to view the files as they were in that
past version.
</p>
<div class="table-responsive">
<table class="table table-condensed table-hover">
<thead>
<tr>
<th>
File
</th>
<th>
Version
</th>
<th>
Author
</th>
<th>
Date
</th>
<th>
Message
</th>
</tr>
</thead>
<tbody>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/stephens999/misc/blob/a415272e8d25afa0d7c854d7b15a57f22f6672e4/analysis/fastica_02.Rmd" target="_blank">a415272</a>
</td>
<td>
Matthew Stephens
</td>
<td>
2025-11-14
</td>
<td>
workflowr::wflow_publish("fastica_02.Rmd")
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/stephens999/misc/fd23328815e329adbc5d36518e81c3f2372eb02c/docs/fastica_02.html" target="_blank">fd23328</a>
</td>
<td>
Matthew Stephens
</td>
<td>
2025-11-11
</td>
<td>
Build site.
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/stephens999/misc/blob/a0618fff0636d6dd24212694aa0cfdf3857539b3/analysis/fastica_02.Rmd" target="_blank">a0618ff</a>
</td>
<td>
Matthew Stephens
</td>
<td>
2025-11-11
</td>
<td>
workflowr::wflow_publish("fastica_02.Rmd")
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/stephens999/misc/da2844711e603f528d87af14f47bad06a2f89602/docs/fastica_02.html" target="_blank">da28447</a>
</td>
<td>
Matthew Stephens
</td>
<td>
2025-11-03
</td>
<td>
Build site.
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/stephens999/misc/blob/59ffdb1e272c1e5a8693750bab7b261bcd56db86/analysis/fastica_02.Rmd" target="_blank">59ffdb1</a>
</td>
<td>
Matthew Stephens
</td>
<td>
2025-11-03
</td>
<td>
workflowr::wflow_publish("fastica_02.Rmd")
</td>
</tr>
</tbody>
</table>
</div>
<hr>
</div>
</div>
</div>
<pre class="r"><code>library(flashier)</code></pre>
<pre><code>Loading required package: ebnm</code></pre>
<pre class="r"><code>library(fastICA)</code></pre>
<div id="introduction" class="section level2">
<h2>Introduction</h2>
<p>I wanted to implement single unit fast ica for myself to better
understand what it is doing. I also compare the single unit solution
with the single unit solution from flashier in a simulation.</p>
</div>
<div id="single-unit-ica" class="section level2">
<h2>Single unit ICA</h2>
<p>This is the basic update for fastICA:</p>
<pre class="r"><code>fastica_r1update = function(X,w){
  w= w/sqrt(sum(w^2))
  P = t(X) %*% w
  G = tanh(P)
  G2 = 1-tanh(P)^2
  w = X %*% G - sum(G2) * w 
  return(w)
}</code></pre>
<p>The following function centers and whitens the data. This code is
based on the fastICA function in the fastICA package. It projects the
columns of X onto the top n.comp PCs. These projections are the rows of
the returned matrix, so the returned matrix has n.comp rows and nrow(X)
columns. It seems it could be better to avoid forming XX’ in some cases
but for now I just followed the fastICA code.</p>
<p>(Actually it seems this should be equivalent to finding the first
n.comp right eigenvectors of the centered X? ie we could replace the
projection step with X’ = UDV’ and take (root-n times) the first k rows
of V’?)</p>
<pre class="r"><code>preprocess = function(X, n.comp=10){
  n &lt;- nrow(X)
  p &lt;- ncol(X)
  X &lt;- scale(X, scale = FALSE)
  X &lt;- t(X)
  
  ## This appears to be equivalant to X1 = t(svd(X)$v[,1:n.comp])       
  V &lt;- X %*% t(X)/n
  s &lt;- La.svd(V)
  D &lt;- diag(c(1/sqrt(s$d)))
  K &lt;- D %*% t(s$u)
  K &lt;- matrix(K[1:n.comp, ], n.comp, p)
  X1 &lt;- K %*% X
  return(X1)
}</code></pre>
</div>
<div id="simulate-data" class="section level2">
<h2>Simulate data</h2>
<p>These are the same simulations as in [fastica_01.html]</p>
<pre class="r"><code>M &lt;- 10000 # Number of variants/samples (rows)
L &lt;- 10    # True number of latent factors
T &lt;- 100   # Number of traits/phenotypes (columns)

s_1 &lt;- 1   # Standard Deviation 1 (Spike component)
s_2 &lt;- 5   # Standard Deviation 2 (Slab component)
eps &lt;- 1e-2 # Standard Deviation for observation noise 

# Set seed for reproducibility
set.seed(42)

# Data Simulation (G = X %*% Y + noise)

# 3.1. Generating Standard Deviation Matrices (a and b)
# Elements are sampled from {s_1, s_2} [1, 2].
sd_choices &lt;- c(s_1, s_2)

# Matrix &#39;a&#39; (M x L): Standard deviations for X (Probabilities p=[0.7, 0.3]) [4]
p_a &lt;- c(0.7, 0.3)
a_vector &lt;- sample(sd_choices, size = M * L, replace = TRUE, prob = p_a)
a &lt;- matrix(a_vector, nrow = M, ncol = L)

# Matrix &#39;b&#39; (L x T): Standard deviations for Y (Probabilities p=[0.8, 0.2]) [4]
p_b &lt;- c(0.8, 0.2)
b_vector &lt;- sample(sd_choices, size = L * T, replace = TRUE, prob = p_b)
b &lt;- matrix(b_vector, nrow = L, ncol = T)

# Generating Latent Factors (X and Y)
# X is drawn from Normal(0, a)
X &lt;- matrix(rnorm(M * L, mean = 0, sd = a), nrow = M, ncol = L)

# Y is drawn from Normal(0, b)
Y &lt;- matrix(rnorm(L * T, mean = 0, sd = b), nrow = L, ncol = T)

# Generating Noise and Final Data Matrix G
# Noise is generated from Normal(0, eps)
noise &lt;- matrix(rnorm(M * T, mean = 0, sd = eps), nrow = M, ncol = T)

# Calculate the final data matrix G = X @ Y + noise
G &lt;- X %*% Y + noise</code></pre>
</div>
<div id="run-single-unit-ica" class="section level2">
<h2>Run single unit ICA</h2>
<p>Here w is a linear combination of the rows of X1, and the goal is to
find a linear combination that makes the result highly non-gaussian.</p>
<pre class="r"><code>X1 = preprocess(G)
w = rnorm(nrow(X1))
for(i in 1:100)
  w = fastica_r1update(X1,w)
cor(X,t(X1) %*% w)</code></pre>
<pre><code>              [,1]
 [1,]  0.007917032
 [2,]  0.016874935
 [3,] -0.003013217
 [4,] -0.014116212
 [5,] -0.022826403
 [6,]  0.012073761
 [7,] -0.013725345
 [8,] -0.999735758
 [9,]  0.019391558
[10,] -0.009698386</code></pre>
<pre class="r"><code>w = w/sqrt(sum(w^2))
s = t(X1) %*% w
a = t(G) %*% s/sum(s^2)</code></pre>
</div>
<div id="compare-with-flashier" class="section level2">
<h2>Compare with flashier</h2>
<p>Here I run flashier (rank 1) using point-laplace. It finds a solution
that is correlated with several of the true “sources” rather than
picking out a single source.</p>
<pre class="r"><code>fit.fl = flash(G, ebnm_fn = ebnm_point_laplace, greedy_Kmax = 1)</code></pre>
<pre><code>Adding factor 1 to flash object...
Wrapping up...
Done.
Nullchecking 1 factors...
Done.</code></pre>
<pre class="r"><code>cor(X, fit.fl$L_pm)</code></pre>
<pre><code>             [,1]
 [1,] -0.38096684
 [2,]  0.18415007
 [3,] -0.08594179
 [4,]  0.13024137
 [5,] -0.17705347
 [6,]  0.56027817
 [7,] -0.11790432
 [8,] -0.61768280
 [9,]  0.25136866
[10,]  0.05943069</code></pre>
<p>Here I try initializing from the fastica solution. It moves away from
that solution to something similar to the solution above.</p>
<pre class="r"><code>fit.fl2 = flash_init(G) |&gt; flash_factors_init(init = list(s,a), ebnm_fn = ebnm_point_laplace) |&gt; flash_backfit()</code></pre>
<pre><code>Backfitting 1 factors (tolerance: 1.49e-02)...
  Difference between iterations is within 1.0e+03...
  Difference between iterations is within 1.0e+02...
  Difference between iterations is within 1.0e+01...
  Difference between iterations is within 1.0e+00...
  Difference between iterations is within 1.0e-01...
  Difference between iterations is within 1.0e-02...
Wrapping up...
Done.</code></pre>
<pre class="r"><code>cor(X, fit.fl2$L_pm)</code></pre>
<pre><code>             [,1]
 [1,] -0.38107694
 [2,]  0.18447165
 [3,] -0.08604185
 [4,]  0.12970939
 [5,] -0.17691546
 [6,]  0.56051773
 [7,] -0.11795167
 [8,] -0.61765857
 [9,]  0.25082905
[10,]  0.05933034</code></pre>
<pre class="r"><code>fit.fl$elbo</code></pre>
<pre><code>[1] -4404522</code></pre>
<pre class="r"><code>fit.fl2$elbo</code></pre>
<pre><code>[1] -4404524</code></pre>
</div>
<div id="understanding-the-result" class="section level2">
<h2>Understanding the result</h2>
<p>Here I look at the “fit” term. We see that the flash solution gives a
better mean squared error than the ICA solution. In fact the ICA
solution is not really very driven by mean squared error: it looks for
directions that are non-gaussian without worrying at all about the mse
(except they have to be linear combinations of the rows of X).</p>
<pre class="r"><code>mean((G-fitted(fit.fl))^2)</code></pre>
<pre><code>[1] 376.2759</code></pre>
<pre class="r"><code>mean((G-fitted(fit.fl2))^2)</code></pre>
<pre><code>[1] 376.2755</code></pre>
<pre class="r"><code>mean((G-s%*%t(a))^2)</code></pre>
<pre><code>[1] 396.8568</code></pre>
<p>This gets me thinking that, in terms of finding the true sources,
maybe flash (rank 1) is over emphasising the fit term relative to the
penalty (non-gaussian) term. Maybe we could improve this by
downweighting the fit term somehow. Here I look at the nuclear norm of
the residuals for the two approaches:</p>
<pre class="r"><code>nuclear_norm = function(X){
  s = svd(X)$d
  return(sum(s))
}
frob_norm = function(X){
  s = svd(X)$d
  return(sqrt(sum(s^2)))
}
(nuclear_norm((G-fitted(fit.fl))) - nuclear_norm((G-s%*%t(a))))/(ncol(G)*nrow(G))</code></pre>
<pre><code>[1] -0.0009582495</code></pre>
<pre class="r"><code>(frob_norm((G-fitted(fit.fl))) - frob_norm((G-s%*%t(a))))/(ncol(G)*nrow(G))</code></pre>
<pre><code>[1] -0.000523434</code></pre>
</div>
<div id="independent-binary-groups-3-groups-of--1"
class="section level2">
<h2>Independent binary groups (3 groups of +-1)</h2>
<p>Here I try simulating 3 binary groups (each an independent 50-50
split in n=100). I use +-1 for the groups here (so it is not a
nonnegative simulation here). Specifically I simulate <span
class="math inline">\(X=LF&#39;+E\)</span> where <span
class="math inline">\(L\)</span> are +-1 and <span
class="math inline">\(F\)</span> are iid normal. I add a small error
term.</p>
<pre class="r"><code>K=3
p = 1000
n = 100
set.seed(1)
L = matrix(-1,nrow=n,ncol=K)
for(i in 1:K){L[sample(1:n,n/2),i]=1}
FF = matrix(rnorm(p*K), nrow = p, ncol=K)
X = L %*% t(FF) + rnorm(n*p,0,0.01)
image(X)</code></pre>
<p><img src="figure/fastica_02.Rmd/unnamed-chunk-10-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>Since <span class="math inline">\(F\)</span> is simulated here to be
independent, it should be that <span class="math inline">\(F&#39;F
\approx I\)</span>, so <span class="math inline">\(XF\)</span> shoudl be
something close to <span class="math inline">\(L\)</span>, and indeed it
is. I’m hoping ICA will find <span
class="math inline">\(W=F\)</span>.</p>
<pre class="r"><code>par(mfcol=c(3,1))
plot(X %*% FF[,1], L[,1])
plot(X %*% FF[,2], L[,2])
plot(X %*% FF[,3], L[,3])</code></pre>
<p><img src="figure/fastica_02.Rmd/unnamed-chunk-11-1.png" width="672" style="display: block; margin: auto;" /></p>
<div id="fastica" class="section level3">
<h3>fastICA</h3>
<p>Single unit fastICA on these data picks out a single source:</p>
<pre class="r"><code>X1 = preprocess(X)
w = rnorm(nrow(X1))
for(i in 1:10)
  w = fastica_r1update(X1,w)
cor(L,t(X1) %*% w)</code></pre>
<pre><code>            [,1]
[1,]  0.09199908
[2,] -0.14565607
[3,] -0.99941252</code></pre>
<p>Here is multi-unit fastICA; it finds all 3 groups essentially
perfectly.</p>
<pre class="r"><code>fit.ica = fastICA(X, n.comp = 3)
apply(abs(cor(L,fit.ica$S)),1, max)</code></pre>
<pre><code>[1] 0.9989443 0.9965059 0.9958627</code></pre>
<pre class="r"><code>par(mfcol=c(2,2))
for(k in 1:3)
  plot(fit.ica$S[,k])</code></pre>
<p><img src="figure/fastica_02.Rmd/unnamed-chunk-13-1.png" width="672" style="display: block; margin: auto;" /></p>
</div>
<div id="flashier" class="section level3">
<h3>flashier</h3>
<p>Running single-unit flashier with point Laplace prior does not find
any group - it finds the first PC.</p>
<pre class="r"><code>fit.fl = flash(X, ebnm_fn = c(ebnm_point_laplace,ebnm_normal), greedy_Kmax = 1)</code></pre>
<pre><code>Adding factor 1 to flash object...
Wrapping up...
Done.
Nullchecking 1 factors...
Done.</code></pre>
<pre class="r"><code>cor(L,fit.fl$L_pm)</code></pre>
<pre><code>           [,1]
[1,] -0.1567018
[2,] -0.8002616
[3,] -0.6939910</code></pre>
<pre class="r"><code>cor(svd(X)$u[,1],fit.fl$L_pm)</code></pre>
<pre><code>          [,1]
[1,] 0.9999963</code></pre>
<p>Similarly, running with backfitting finds the first 3 PCs.</p>
<pre class="r"><code>fit.fl = flash(X, ebnm_fn = c(ebnm_point_laplace,ebnm_normal), greedy_Kmax = 10,backfit=TRUE)</code></pre>
<pre><code>Adding factor 1 to flash object...
Adding factor 2 to flash object...
Adding factor 3 to flash object...
Adding factor 4 to flash object...
Factor doesn&#39;t significantly increase objective and won&#39;t be added.
Wrapping up...
Done.
Backfitting 3 factors (tolerance: 1.49e-03)...
  Difference between iterations is within 1.0e+05...
  Difference between iterations is within 1.0e+04...
  Difference between iterations is within 1.0e+03...
  Difference between iterations is within 1.0e+02...
  Difference between iterations is within 1.0e+01...
Wrapping up...
Done.
Nullchecking 3 factors...
Done.</code></pre>
<pre class="r"><code>cor(L,fit.fl$L_pm)</code></pre>
<pre><code>           [,1]        [,2]       [,3]
[1,] -0.1566870 -0.94939845 -0.2720530
[2,] -0.8002638 -0.08025245  0.5942468
[3,] -0.6939936  0.37506211 -0.6146585</code></pre>
<pre class="r"><code>cor(svd(X)$u[,1:3],fit.fl$L_pm)</code></pre>
<pre><code>              [,1]         [,2]          [,3]
[1,]  0.9999966324 0.0024234410  0.0003082603
[2,] -0.0025763629 0.9999967966  0.0006660919
[3,]  0.0003124162 0.0007305277 -0.9999997306</code></pre>
<p>Here I try with a (approximate) Bernoulli (+-1) prior. First I define
the ebnm_symmetric_bernoulli function to compute the posterior for this
prior:</p>
<pre class="r"><code>ebnm_symmetric_bernoulli = flash_ebnm(
    prior_family = &quot;normal_scale_mixture&quot;,
    fix_g = TRUE,
    g_init = ashr::normalmix(pi = c(0.5, 0.5),
                             mean = c(-1, 1),
                             sd = 1e-8))</code></pre>
<p>Single unit flash with this prior does not find a good solution.</p>
<pre class="r"><code>fit.fl = flash(X, ebnm_fn = c(ebnm_symmetric_bernoulli,ebnm_normal), greedy_Kmax = 1)</code></pre>
<pre><code>Adding factor 1 to flash object...
Wrapping up...
Done.
Nullchecking 1 factors...
Done.</code></pre>
<pre class="r"><code>cor(L,fit.fl$L_pm)</code></pre>
<pre><code>      [,1]
[1,] -0.40
[2,] -0.64
[3,] -0.52</code></pre>
<pre class="r"><code>cor(svd(X)$u[,1],fit.fl$L_pm)</code></pre>
<pre><code>          [,1]
[1,] 0.8279994</code></pre>
<pre class="r"><code>par(mfcol=c(2,1))
plot(fit.fl$L_pm)
plot(X %*% fit.fl$F_pm)</code></pre>
<p><img src="figure/fastica_02.Rmd/unnamed-chunk-17-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>But with backfitting it does find the correct solution:</p>
<pre class="r"><code>fit.fl = flash(X, ebnm_fn = c(ebnm_symmetric_bernoulli,ebnm_normal) , greedy_Kmax = 10,backfit=TRUE)</code></pre>
<pre><code>Adding factor 1 to flash object...
Adding factor 2 to flash object...
Adding factor 3 to flash object...
Adding factor 4 to flash object...
Adding factor 5 to flash object...
Adding factor 6 to flash object...
Adding factor 7 to flash object...
Adding factor 8 to flash object...
Adding factor 9 to flash object...
Factor doesn&#39;t significantly increase objective and won&#39;t be added.
Wrapping up...
Done.
Backfitting 8 factors (tolerance: 1.49e-03)...
  Difference between iterations is within 1.0e+05...
  Difference between iterations is within 1.0e+04...
  Difference between iterations is within 1.0e+03...
  --Estimate of factor 8 is numerically zero!
  Difference between iterations is within 1.0e+02...
  Difference between iterations is within 1.0e+01...
  Difference between iterations is within 1.0e+00...
  --Estimate of factor 7 is numerically zero!
  --Estimate of factor 6 is numerically zero!
  Difference between iterations is within 1.0e-01...
  --Estimate of factor 5 is numerically zero!
  --Estimate of factor 1 is numerically zero!
  Difference between iterations is within 1.0e-02...
  Difference between iterations is within 1.0e-03...
Wrapping up...
Done.
Nullchecking 8 factors...
  5 factors are identically zero.
Wrapping up...
  Removed 5 factors.
Done.</code></pre>
<pre class="r"><code>cor(L,fit.fl$L_pm)</code></pre>
<pre><code>      [,1]  [,2] [,3]
[1,] -1.00 -0.08 0.04
[2,] -0.04  0.16 1.00
[3,]  0.08  1.00 0.16</code></pre>
</div>
</div>
<div id="independent-binary-groups-3-groups-of-01"
class="section level2">
<h2>Independent binary groups (3 groups of 0,1)</h2>
<p>Now I redo those simulations, but with 0-1 groups instead of +-1.</p>
<pre class="r"><code>K=3
p = 1000
n = 100
set.seed(1)
L = matrix(0,nrow=n,ncol=K)
for(i in 1:K){L[sample(1:n,n/2),i]=1}
FF = matrix(rnorm(p*K), nrow = p, ncol=K)
X = L %*% t(FF) + rnorm(n*p,0,0.01)
image(X)</code></pre>
<p><img src="figure/fastica_02.Rmd/unnamed-chunk-19-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>Since <span class="math inline">\(F\)</span> is simulated here to be
independent, it should be that <span class="math inline">\(F&#39;F
\approx I\)</span>, so <span class="math inline">\(XF\)</span> shoudl be
something close to <span class="math inline">\(L\)</span>, and indeed it
is. I’m hoping ICA will find <span
class="math inline">\(W=F\)</span>.</p>
<pre class="r"><code>par(mfcol=c(3,1))
plot(X %*% FF[,1], L[,1])
plot(X %*% FF[,2], L[,2])
plot(X %*% FF[,3], L[,3])</code></pre>
<p><img src="figure/fastica_02.Rmd/unnamed-chunk-20-1.png" width="672" style="display: block; margin: auto;" /></p>
<div id="fastica-1" class="section level3">
<h3>fastICA</h3>
<p>Single unit fastICA on these data picks out a single source:</p>
<pre class="r"><code>X1 = preprocess(X)
w = rnorm(nrow(X1))
for(i in 1:10)
  w = fastica_r1update(X1,w)
cor(L,t(X1) %*% w)</code></pre>
<pre><code>           [,1]
[1,]  0.0909585
[2,] -0.1472225
[3,] -0.9995281</code></pre>
<p>Here is multi-unit fastICA; it finds all 3 groups essentially
perfectly.</p>
<pre class="r"><code>fit.ica = fastICA(X, n.comp = 3)
apply(abs(cor(L,fit.ica$S)),1, max)</code></pre>
<pre><code>[1] 0.9989442 0.9965061 0.9958623</code></pre>
<pre class="r"><code>par(mfcol=c(2,2))
for(k in 1:3)
  plot(fit.ica$S[,k])</code></pre>
<p><img src="figure/fastica_02.Rmd/unnamed-chunk-22-1.png" width="672" style="display: block; margin: auto;" /></p>
</div>
<div id="flashier-1" class="section level3">
<h3>flashier</h3>
<p>Running single-unit flashier with point exponential prior does not
find any group - it finds the first PC.</p>
<pre class="r"><code>fit.fl = flash(X, ebnm_fn = c(ebnm_point_exponential,ebnm_normal), greedy_Kmax = 1)</code></pre>
<pre><code>Adding factor 1 to flash object...
Wrapping up...
Done.
Nullchecking 1 factors...
Done.</code></pre>
<pre class="r"><code>cor(L,fit.fl$L_pm)</code></pre>
<pre><code>          [,1]
[1,] 0.5227276
[2,] 0.6792148
[3,] 0.5977773</code></pre>
<pre class="r"><code>cor(svd(X)$u[,1],fit.fl$L_pm)</code></pre>
<pre><code>           [,1]
[1,] -0.9999988</code></pre>
<p>Running with backfitting finds 5 factors, none of them correct.</p>
<pre class="r"><code>fit.fl = flash(X, ebnm_fn = c(ebnm_point_exponential,ebnm_normal), greedy_Kmax = 10,backfit=TRUE)</code></pre>
<pre><code>Adding factor 1 to flash object...
Adding factor 2 to flash object...
Adding factor 3 to flash object...
Adding factor 4 to flash object...
Adding factor 5 to flash object...
Adding factor 6 to flash object...
Adding factor 7 to flash object...
Adding factor 8 to flash object...
Factor doesn&#39;t significantly increase objective and won&#39;t be added.
Wrapping up...
Done.
Backfitting 7 factors (tolerance: 1.49e-03)...
  Difference between iterations is within 1.0e+05...
  Difference between iterations is within 1.0e+04...
  Difference between iterations is within 1.0e+03...
  Difference between iterations is within 1.0e+02...
  Difference between iterations is within 1.0e+01...
  Difference between iterations is within 1.0e+00...
  --Estimate of factor 6 is numerically zero!
  --Estimate of factor 7 is numerically zero!
  Difference between iterations is within 1.0e-01...
  Difference between iterations is within 1.0e-02...
  --Maximum number of iterations reached!
Wrapping up...
Done.
Nullchecking 7 factors...
  2 factors are identically zero.
Wrapping up...
  Removed 2 factors.
Done.</code></pre>
<pre class="r"><code>cor(L,fit.fl$L_pm)</code></pre>
<pre><code>          [,1]       [,2]       [,3]       [,4]       [,5]
[1,] 0.5216345  0.7497056 -0.3678773 -0.2471044 -0.2220610
[2,] 0.6777868 -0.2532741 -0.1322539  0.7498331 -0.4353849
[3,] 0.5983102 -0.3683479  0.7494706 -0.1315798  0.2212696</code></pre>
<pre class="r"><code>cor(svd(X)$u[,1:3],fit.fl$L_pm)</code></pre>
<pre><code>           [,1]        [,2]       [,3]       [,4]       [,5]
[1,] -0.9988877 -0.06100998 -0.1368803 -0.2200027  0.2469289
[2,]  0.0581783 -0.82837620  0.6308183  0.3057501  0.1792939
[3,]  0.0605365 -0.11628327 -0.5469159  0.7742343 -0.4737231</code></pre>
<p>Here I try with a Bernoulli (0,1) prior. First I define the
ebnm_bernoulli function to compute the posterior for this prior:</p>
<pre class="r"><code>ebnm_bernoulli = flash_ebnm(
    prior_family = &quot;normal_scale_mixture&quot;,
    fix_g = TRUE,
    g_init = ashr::normalmix(pi = c(0.5, 0.5),
                             mean = c(0, 1),
                             sd = 1e-8))</code></pre>
<p>Single unit flash with this prior does not find a good solution.</p>
<pre class="r"><code>fit.fl = flash(X, ebnm_fn = c(ebnm_bernoulli,ebnm_normal), greedy_Kmax = 1)</code></pre>
<pre><code>Adding factor 1 to flash object...
Wrapping up...
Done.
Nullchecking 1 factors...
Done.</code></pre>
<pre class="r"><code>cor(L,fit.fl$L_pm)</code></pre>
<pre><code>          [,1]
[1,] 0.4034733
[2,] 0.4034733
[3,] 0.4034733</code></pre>
<pre class="r"><code>cor(svd(X)$u[,1],fit.fl$L_pm)</code></pre>
<pre><code>           [,1]
[1,] -0.6712566</code></pre>
<pre class="r"><code>par(mfcol=c(2,1))
plot(fit.fl$L_pm)
plot(X %*% fit.fl$F_pm)</code></pre>
<p><img src="figure/fastica_02.Rmd/unnamed-chunk-26-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>In this case backfitting also doesn’t work.</p>
<pre class="r"><code>fit.fl = flash(X, ebnm_fn = c(ebnm_bernoulli,ebnm_normal) , greedy_Kmax = 10,backfit=TRUE)</code></pre>
<pre><code>Adding factor 1 to flash object...
Adding factor 2 to flash object...
Adding factor 3 to flash object...
Adding factor 4 to flash object...
Adding factor 5 to flash object...
Adding factor 6 to flash object...
Adding factor 7 to flash object...
Adding factor 8 to flash object...
Adding factor 9 to flash object...
Adding factor 10 to flash object...
Wrapping up...
Done.
Backfitting 10 factors (tolerance: 1.49e-03)...
  Difference between iterations is within 1.0e+04...
  Difference between iterations is within 1.0e+03...
  Difference between iterations is within 1.0e+02...
  Difference between iterations is within 1.0e+01...
  Difference between iterations is within 1.0e+00...
  Difference between iterations is within 1.0e-01...
  Difference between iterations is within 1.0e-02...
  Difference between iterations is within 1.0e-03...
Wrapping up...
Done.
Nullchecking 10 factors...
Factor5set to zero, increasing objective by 1.229e-06.
Factor6set to zero, increasing objective by 1.085e-05.
Factor7set to zero, increasing objective by 1.305e-06.
Factor8set to zero, increasing objective by 3.321e-06.
Factor9set to zero, increasing objective by 2.710e-06.
Factor10set to zero, increasing objective by 2.528e-06.
Wrapping up...
  Removed 6 factors.
Done.</code></pre>
<pre class="r"><code>cor(L,fit.fl$L_pm)</code></pre>
<pre><code>          [,1]   [,2]   [,3]   [,4]
[1,] 0.4034733 -0.750  0.250  0.375
[2,] 0.4034733  0.250 -0.750  0.125
[3,] 0.4034733  0.375  0.125 -0.750</code></pre>
<p>Try generalized binary - also fails.</p>
<pre class="r"><code>fit.fl = flash(X, ebnm_fn = c(ebnm_point_exponential,ebnm_normal), greedy_Kmax = 100, backfit=TRUE)</code></pre>
<pre><code>Adding factor 1 to flash object...
Adding factor 2 to flash object...
Adding factor 3 to flash object...
Adding factor 4 to flash object...
Adding factor 5 to flash object...
Adding factor 6 to flash object...
Adding factor 7 to flash object...
Adding factor 8 to flash object...
Factor doesn&#39;t significantly increase objective and won&#39;t be added.
Wrapping up...
Done.
Backfitting 7 factors (tolerance: 1.49e-03)...
  Difference between iterations is within 1.0e+05...
  Difference between iterations is within 1.0e+04...
  Difference between iterations is within 1.0e+03...
  Difference between iterations is within 1.0e+02...
  Difference between iterations is within 1.0e+01...
  Difference between iterations is within 1.0e+00...
  --Estimate of factor 6 is numerically zero!
  --Estimate of factor 7 is numerically zero!
  Difference between iterations is within 1.0e-01...
  Difference between iterations is within 1.0e-02...
  --Maximum number of iterations reached!
Wrapping up...
Done.
Nullchecking 7 factors...
  2 factors are identically zero.
Wrapping up...
  Removed 2 factors.
Done.</code></pre>
<pre class="r"><code>apply(abs(cor(L,fit.fl$L_pm)),1,max)</code></pre>
<pre><code>[1] 0.7497056 0.7498331 0.7494706</code></pre>
<pre class="r"><code>fit.fl.gb = flash_init(X) |&gt; flash_factors_init(init = list(fit.fl$L_pm, fit.fl$F_pm), ebnm_fn = c(ebnm_generalized_binary,ebnm_normal)) |&gt; flash_backfit()</code></pre>
<pre><code>Backfitting 5 factors (tolerance: 1.49e-03)...
  Difference between iterations is within 1.0e+01...
  Difference between iterations is within 1.0e+00...
  Difference between iterations is within 1.0e-01...
  Difference between iterations is within 1.0e-02...
  Difference between iterations is within 1.0e-03...
Wrapping up...
Done.</code></pre>
<pre class="r"><code>apply(abs(cor(L,fit.fl.gb$L_pm)),1,max)</code></pre>
<pre><code>[1] 0.7464413 0.7418248 0.7418114</code></pre>
<p>Single unit flash with GB prior initialized at ICA solution:</p>
<pre class="r"><code>Lhat = t(X1) %*% w
Fhat = t(X) %*% Lhat / sum(Lhat^2) 
fit.fl.gb = flash_init(X) |&gt; flash_factors_init(init = list( cbind(Lhat),cbind(Fhat)), ebnm_fn = c(ebnm_generalized_binary,ebnm_normal)) |&gt; flash_backfit()</code></pre>
<pre><code>Backfitting 1 factors (tolerance: 1.49e-03)...
  Difference between iterations is within 1.0e+04...
  Difference between iterations is within 1.0e+03...
  Difference between iterations is within 1.0e+02...
  Difference between iterations is within 1.0e+01...
  Difference between iterations is within 1.0e+00...
  Difference between iterations is within 1.0e-01...
Wrapping up...
Done.</code></pre>
<pre class="r"><code>cor(L,fit.fl.gb$L_pm)</code></pre>
<pre><code>          [,1]
[1,] 0.5248171
[2,] 0.6770598
[3,] 0.5976217</code></pre>
<p>Single unit flash with bernoulli prior initialized at ICA
solution:</p>
<pre class="r"><code>Lhat = t(X1) %*% w/sqrt(p)
Fhat = t(X) %*% Lhat / sum(Lhat^2) 
fit.fl.b = flash_init(X) |&gt; flash_factors_init(init = list( cbind(Lhat),cbind(Fhat)), ebnm_fn = c(ebnm_bernoulli,ebnm_normal)) |&gt; flash_backfit()</code></pre>
<pre><code>Backfitting 1 factors (tolerance: 1.49e-03)...
  --Estimate of factor 1 is numerically zero!
Wrapping up...
Done.</code></pre>
<pre class="r"><code>cor(L,fit.fl.b$L_pm)</code></pre>
<pre><code>           [,1]
[1,] -0.3408647
[2,] -0.6322558
[3,] -0.7695170</code></pre>
<p>Single unit flash with bernoulli prior initialized at true value - I
was suprised this doesn’t work and thought maybe I was doing something
wrong. However, I think that what is happening is that now the Ls are
not close to orthogonal because of the non-negative values. In contrast,
the previous (+-1) Ls were close to orthogonal. This seems to have a
major impact. I should think harder about this and what it implies about
how to deal with binary groups.</p>
<pre class="r"><code>Lhat = L[,1]
Fhat = FF[,1]
fit.fl.b = flash_init(X) |&gt; flash_factors_init(init = list( cbind(Lhat),cbind(Fhat)), ebnm_fn = c(ebnm_bernoulli,ebnm_normal)) |&gt; flash_backfit(maxiter=2)</code></pre>
<pre><code>Backfitting 1 factors (tolerance: 1.49e-03)...
  --Maximum number of iterations reached!
Wrapping up...
Done.</code></pre>
<pre class="r"><code>cor(L,fit.fl.b$L_pm)</code></pre>
<pre><code>     Lhat
[1,] 0.40
[2,] 0.64
[3,] 0.52</code></pre>
</div>
</div>
<div id="independent-binary-groups-9-groups" class="section level2">
<h2>Independent binary groups (9 groups)</h2>
<p>Here I simulate 9 groups to make the problem harder. But still there
is a very clear non-gaussian signal in the data.</p>
<pre class="r"><code>K=9
p = 1000
n = 100
set.seed(1)
L = matrix(-1,nrow=n,ncol=K)
for(i in 1:K){L[sample(1:n,50),i]=1}
FF = matrix(rnorm(p*K), nrow = p, ncol=K)

X = L %*% t(FF) + rnorm(n*p,0,0.01)
plot(X %*% FF[,1])</code></pre>
<p><img src="figure/fastica_02.Rmd/unnamed-chunk-32-1.png" width="672" style="display: block; margin: auto;" /></p>
<div id="fastica-2" class="section level3">
<h3>fastICA</h3>
<p>Running single unit fastICA on these data picks out a single
source:</p>
<pre class="r"><code>X1 = preprocess(X)
w = rnorm(nrow(X1))
for(i in 1:100)
  w = fastica_r1update(X1,w)
cor(L,t(X1) %*% w)</code></pre>
<pre><code>               [,1]
 [1,] -8.889918e-09
 [2,] -3.999999e-02
 [3,] -2.000000e-01
 [4,] -4.000000e-02
 [5,] -9.999999e-01
 [6,] -8.000001e-02
 [7,]  1.200000e-01
 [8,]  4.000002e-02
 [9,] -1.200000e-01</code></pre>
</div>
</div>
<div id="smaller-binary-groups-3-groups" class="section level2">
<h2>Smaller binary groups (3 groups)</h2>
<p>Here I simulate 3 groups, with only 20 members each, to make the
problem harder. Again the nongaussian signal is there but now it might
be harder to find, or maybe it will just not score as highly in terms of
non-gaussianity?</p>
<pre class="r"><code>K=3
p = 1000
n = 100
set.seed(1)
L = matrix(-1,nrow=n,ncol=K)
for(i in 1:K){L[sample(1:n,20),i]=1}
FF = matrix(rnorm(p*K), nrow = p, ncol=K)

X = L %*% t(FF) + rnorm(n*p,0,0.01)
plot(X %*% FF[,1])</code></pre>
<p><img src="figure/fastica_02.Rmd/unnamed-chunk-34-1.png" width="672" style="display: block; margin: auto;" /></p>
<div id="fastica-3" class="section level3">
<h3>fastICA</h3>
<p>Running single unit fastICA on these data does not pick out a single
source:</p>
<pre class="r"><code>X1 = preprocess(X)
w = rnorm(nrow(X1))
for(i in 1:100)
  w = fastica_r1update(X1,w)
cor(L,t(X1) %*% w)</code></pre>
<pre><code>            [,1]
[1,] -0.09720849
[2,]  0.39491239
[3,]  0.06322010</code></pre>
<pre class="r"><code>plot(t(X1) %*% w)</code></pre>
<p><img src="figure/fastica_02.Rmd/unnamed-chunk-35-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>Try initializing near a true source. It moves away from it, and
indeed finds a solution with a better value of its logcosh objective
function.</p>
<pre class="r"><code>w = X1 %*% L[,1]
plot(t(X1) %*% w)</code></pre>
<p><img src="figure/fastica_02.Rmd/unnamed-chunk-36-1.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>init_val = t(X1) %*% w
init_val = init_val/sqrt(mean(init_val^2))

for(i in 1:100)
  w = fastica_r1update(X1,w)
cor(L,t(X1) %*% w)</code></pre>
<pre><code>             [,1]
[1,] -0.189724430
[2,]  0.087759753
[3,]  0.008005991</code></pre>
<pre class="r"><code>plot(t(X1) %*% w)</code></pre>
<p><img src="figure/fastica_02.Rmd/unnamed-chunk-36-2.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>final_val = t(X1) %*% w
final_val = final_val/sqrt(mean(final_val^2))</code></pre>
<p>Looking at the mean logcosh of the initial value, we see it is
actually very close to that of a normal. The algorithm moves it further
away, so is indeed doing what it should do. Note that the logcosh of
bernoulli(+-1) is about 0.433, and above the logcosh for a normal, 0.38.
So what is happening is that the “unbalanced” (approximate) bernoulli
distribution of our source, does not have a large logcosh value, and
indeed does not even have a larger logcosh distribution than a
normal.</p>
<pre class="r"><code>mean(log(cosh(init_val)))</code></pre>
<pre><code>[1] 0.3610922</code></pre>
<pre class="r"><code>mean(log(cosh(final_val)))</code></pre>
<pre><code>[1] 0.3958629</code></pre>
<pre class="r"><code>mean(log(cosh(rnorm(10000))))</code></pre>
<pre><code>[1] 0.3682596</code></pre>
<pre class="r"><code>log(cosh(1))</code></pre>
<pre><code>[1] 0.4337808</code></pre>
<p>Thoughts on this: note that the expected log cosh value is not
invariant to shifts of the distribution. We could shift our asymmetric
bernoulli distribution, and scale to have variance 1, and it’s expected
log-cosh would be the same as the original bernoulli. However, fastICA
does not do this shifting, and so the expected log-cosh value depends on
the mean of the distribution. Maybe fastICA could be improved for this
example by modifying the objective function to be shift invariant?</p>
</div>
<div id="flashier-2" class="section level3">
<h3>flashier</h3>
<p>Neither does running flashier:</p>
<pre class="r"><code>fit.fl = flash(X, ebnm_fn = c(ebnm_point_exponential,ebnm_point_laplace), greedy_Kmax = 1)</code></pre>
<pre><code>Adding factor 1 to flash object...
Wrapping up...
Done.
Nullchecking 1 factors...
Done.</code></pre>
<pre class="r"><code>cor(L,fit.fl$L_pm)</code></pre>
<pre><code>           [,1]
[1,] -0.5473206
[2,] -0.5509876
[3,] -0.5392459</code></pre>
</div>
<div id="multiunit" class="section level3">
<h3>Multiunit</h3>
<p>Run multi-unit ICA. It doesn’t really help much?</p>
<pre class="r"><code>fit.ica = fastICA(X, n.comp = 9)
apply(abs(cor(L,fit.ica$S)),1, max)</code></pre>
<pre><code>[1] 0.5301741 0.5551561 0.5043458</code></pre>
<p>Here is multi-unit flashier; it does a better job, but not
perfect.</p>
<pre class="r"><code>fit.fl = flash(X, ebnm_fn = c(ebnm_point_exponential,ebnm_normal), greedy_Kmax = 9, backfit=TRUE)</code></pre>
<pre><code>Adding factor 1 to flash object...
Adding factor 2 to flash object...
Adding factor 3 to flash object...
Adding factor 4 to flash object...
Adding factor 5 to flash object...
Adding factor 6 to flash object...
Adding factor 7 to flash object...
Adding factor 8 to flash object...
Adding factor 9 to flash object...
Wrapping up...
Done.
Backfitting 9 factors (tolerance: 1.49e-03)...
  Difference between iterations is within 1.0e+05...
  Difference between iterations is within 1.0e+04...
  Difference between iterations is within 1.0e+03...
  Difference between iterations is within 1.0e+02...
  --Estimate of factor 8 is numerically zero!
  --Estimate of factor 8 is numerically zero!
  Difference between iterations is within 1.0e+01...
  Difference between iterations is within 1.0e+00...
  --Estimate of factor 9 is numerically zero!
  --Estimate of factor 6 is numerically zero!
  --Estimate of factor 6 is numerically zero!
  --Estimate of factor 7 is numerically zero!
  --Estimate of factor 7 is numerically zero!
  --Estimate of factor 7 is numerically zero!
  --Maximum number of iterations reached!
Wrapping up...
Done.
Nullchecking 9 factors...
  4 factors are identically zero.
Wrapping up...
  Removed 4 factors.
Done.</code></pre>
<pre class="r"><code>apply(abs(cor(L,fit.fl$L_pm)),1,max)</code></pre>
<pre><code>[1] 0.9909129 0.9824303 0.9674084</code></pre>
<pre class="r"><code>fit.fl.gb = flash_init(X) |&gt; flash_factors_init(init = list(fit.fl$L_pm, fit.fl$F_pm), ebnm_fn = c(ebnm_generalized_binary,ebnm_normal)) |&gt; flash_backfit()</code></pre>
<pre><code>Backfitting 5 factors (tolerance: 1.49e-03)...
  Difference between iterations is within 1.0e+00...
  Difference between iterations is within 1.0e-01...
  Difference between iterations is within 1.0e-02...
  Difference between iterations is within 1.0e-03...
Wrapping up...
Done.</code></pre>
<pre class="r"><code>apply(abs(cor(L,fit.fl.gb$L_pm)),1,max)</code></pre>
<pre><code>[1] 0.9976096 0.9905730 0.9802214</code></pre>
</div>
</div>
<div id="smaller-binary-groups-9-groups" class="section level2">
<h2>Smaller binary groups (9 groups)</h2>
<p>Here I simulate 9 groups with only 20 members each, to make the
problem harder again. Again the nongaussian signal is there. ICA won’t
work here (not shown for brevity); flashier does somewhat OK, but maybe
could be improved?</p>
<pre class="r"><code>K=9
p = 1000
n = 100
set.seed(1)
L = matrix(0,nrow=n,ncol=K)
for(i in 1:K){L[sample(1:n,20),i]=1}
FF = matrix(rnorm(p*K), nrow = p, ncol=K)

X = L %*% t(FF) + rnorm(n*p,0,0.01)
plot(X %*% FF[,1])</code></pre>
<p><img src="figure/fastica_02.Rmd/unnamed-chunk-41-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>Here is multi-unit flashier; it does a better job, but not
perfect.</p>
<pre class="r"><code>fit.fl = flash(X, ebnm_fn = c(ebnm_point_exponential,ebnm_normal), greedy_Kmax = 9, backfit=TRUE)</code></pre>
<pre><code>Adding factor 1 to flash object...
Adding factor 2 to flash object...
Adding factor 3 to flash object...
Adding factor 4 to flash object...
Adding factor 5 to flash object...
Adding factor 6 to flash object...
Adding factor 7 to flash object...
Adding factor 8 to flash object...
Adding factor 9 to flash object...
Wrapping up...
Done.
Backfitting 9 factors (tolerance: 1.49e-03)...
  Difference between iterations is within 1.0e+04...
  Difference between iterations is within 1.0e+03...
  Difference between iterations is within 1.0e+02...
  Difference between iterations is within 1.0e+01...
  Difference between iterations is within 1.0e+00...
  Difference between iterations is within 1.0e-01...
  Difference between iterations is within 1.0e-02...
  --Maximum number of iterations reached!
Wrapping up...
Done.
Nullchecking 9 factors...
Done.</code></pre>
<pre class="r"><code>apply(abs(cor(L,fit.fl$L_pm)),1,max)</code></pre>
<pre><code>[1] 0.8266448 0.9127410 0.9613268 0.9354222 0.9138529 0.8364142 0.6324835
[8] 0.8612061 0.9465002</code></pre>
<pre class="r"><code>fit.fl.gb = flash_init(X) |&gt; flash_factors_init(init = list(fit.fl$L_pm, fit.fl$F_pm), ebnm_fn = c(ebnm_generalized_binary,ebnm_normal)) |&gt; flash_backfit()</code></pre>
<pre><code>Backfitting 9 factors (tolerance: 1.49e-03)...
  Difference between iterations is within 1.0e+01...
  Difference between iterations is within 1.0e+00...
  Difference between iterations is within 1.0e-01...
  Difference between iterations is within 1.0e-02...
  --Maximum number of iterations reached!
Wrapping up...
Done.</code></pre>
<pre class="r"><code>apply(abs(cor(L,fit.fl.gb$L_pm)),1,max)</code></pre>
<pre><code>[1] 0.8286910 0.9124418 0.9585522 0.9339699 0.9116221 0.8391904 0.6321243
[8] 0.8615571 0.9438830</code></pre>
<br>
<p>
<button type="button" class="btn btn-default btn-workflowr btn-workflowr-sessioninfo" data-toggle="collapse" data-target="#workflowr-sessioninfo" style="display: block;">
<span class="glyphicon glyphicon-wrench" aria-hidden="true"></span>
Session information
</button>
</p>
<div id="workflowr-sessioninfo" class="collapse">
<pre class="r"><code>sessionInfo()</code></pre>
<pre><code>R version 4.4.2 (2024-10-31)
Platform: aarch64-apple-darwin20
Running under: macOS Sequoia 15.6.1

Matrix products: default
BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib 
LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

time zone: America/Chicago
tzcode source: internal

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] fastICA_1.2-7   flashier_1.0.56 ebnm_1.1-34    

loaded via a namespace (and not attached):
 [1] softImpute_1.4-3     gtable_0.3.6         xfun_0.52           
 [4] bslib_0.9.0          ggplot2_3.5.2        htmlwidgets_1.6.4   
 [7] ggrepel_0.9.6        lattice_0.22-6       quadprog_1.5-8      
[10] vctrs_0.6.5          tools_4.4.2          generics_0.1.4      
[13] parallel_4.4.2       Polychrome_1.5.4     tibble_3.3.0        
[16] pkgconfig_2.0.3      Matrix_1.7-2         data.table_1.17.6   
[19] SQUAREM_2021.1       RColorBrewer_1.1-3   RcppParallel_5.1.10 
[22] scatterplot3d_0.3-44 lifecycle_1.0.4      truncnorm_1.0-9     
[25] compiler_4.4.2       farver_2.1.2         stringr_1.5.1       
[28] git2r_0.35.0         progress_1.2.3       RhpcBLASctl_0.23-42 
[31] httpuv_1.6.15        htmltools_0.5.8.1    sass_0.4.10         
[34] lazyeval_0.2.2       yaml_2.3.10          plotly_4.11.0       
[37] crayon_1.5.3         tidyr_1.3.1          later_1.4.2         
[40] pillar_1.10.2        jquerylib_0.1.4      whisker_0.4.1       
[43] uwot_0.2.3           cachem_1.1.0         trust_0.1-8         
[46] gtools_3.9.5         tidyselect_1.2.1     digest_0.6.37       
[49] Rtsne_0.17           stringi_1.8.7        purrr_1.0.4         
[52] dplyr_1.1.4          ashr_2.2-66          splines_4.4.2       
[55] cowplot_1.1.3        rprojroot_2.0.4      fastmap_1.2.0       
[58] grid_4.4.2           colorspace_2.1-1     cli_3.6.5           
[61] invgamma_1.1         magrittr_2.0.3       prettyunits_1.2.0   
[64] scales_1.4.0         promises_1.3.3       horseshoe_0.2.0     
[67] httr_1.4.7           rmarkdown_2.29       fastTopics_0.7-07   
[70] deconvolveR_1.2-1    workflowr_1.7.1      hms_1.1.3           
[73] pbapply_1.7-2        evaluate_1.0.4       knitr_1.50          
[76] viridisLite_0.4.2    irlba_2.3.5.1        rlang_1.1.6         
[79] Rcpp_1.0.14          mixsqp_0.3-54        glue_1.8.0          
[82] rstudioapi_0.17.1    jsonlite_2.0.0       R6_2.6.1            
[85] fs_1.6.6            </code></pre>
</div>
</div>
</div>
</div>
</div>
</div>
</div>


<!-- Adjust MathJax settings so that all math formulae are shown using
TeX fonts only; see
https://docs.mathjax.org/en/latest/web/configuration.html. This will make
the presentation more consistent at the cost of the webpage sometimes
taking slightly longer to load. Note that this only works because the
footer is added to webpages before the MathJax javascript. -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    "HTML-CSS": { availableFonts: ["TeX"] }
  });
</script>




</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // temporarily add toc-ignore selector to headers for the consistency with Pandoc
    $('.unlisted.unnumbered').addClass('toc-ignore')

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
